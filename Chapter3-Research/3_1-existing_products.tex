\subsection{Existing Products and Projects}
% how have other projects and products used similar strategies to FORWARD?

\noindent There have been numerous efforts made by researchers to develop smart walkers using the available technologies. Perhaps the seminal work in this growing field of research and development is \cite{PAMM}. This group was the first to propose a smart walker project with localization, mobility control, and object avoidance. In the following sections we seek to analyze these technologies and methods in a way that identifies which of such will be most desired for our specific system, taking into consideration many factors, some of which being: cost, attainability, integration complexity, and performance.

%% Toby research here
\subsubsection{Current Walker Sensing Applications}
\noindent In the smart walker prototype created in \cite{Mostofa}, nine HC-SR04 ultrasonic sensors are arrayed along the front of the walker. Seven face forward, while the remaining two point perpendicularly to the walker motion and opposite to each other. This setup provides a continuous reading of the walker's forward hemisphere with a detection range of 200cm. Our team asks the question, can obstacle detection and notification be achieved with a more discrete array of sensors stowed onto the walker frame? What is the operational FOV for ultrasonic sensors? Can the amount be reduced? How will the introduction of LiDAR and camera technology affect the ultrasonic approach?\\

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{./Images/mostafa9.png}
	\caption{\label{fig:mostafa9}"Rollator" with nine HC-SR04 sensors \cite{Mostofa}}
\end{figure}

\noindent Robotics are a popular use of LiDAR, often able to achieve feats such as autonomous delivery. However, many researchers have also introduced laser sensing methods and other waves near infrared in order to provide ranging data to mobile systems, which in our case is the walker. A senior design group at Michigan State University expanded on this \cite{mstate}.\\

\noindent In \cite{FallDetect}, the group implements one of FORWARD's stretch features with an unorthodox yet clever utilization of LiDAR and sensor fusion. In order to equip the walker with fall detection, both ultrasonic and laser sensors are installed near the footstep bay of the walker. They also add force sensors in the handlebars. The feedback provided by the sensing system is whether the user is walking uprightly. If the user began to fall, the laser sensors would reflect their feet moving out of view, and likely the force sensors would experience more pressure as the user reacted to a slip.\\

\noindent This walker does not employ GPS. We are not looking to track the location continuously. This technology has more of a place within the application of health monitoring and emergency alerts.\\

%% Morgan and Toby
\subsubsection{Current Walker Stability Applications}
\noindent The byACRE Ultralight Rollator \cite{byACRE} is among a few walkers to feature stability assistance. Initial analysis reveals that this is nothing more than smoothed turning via pneumatic control. The U-STEP Neuro \cite{ustep} is another that features curb lifting, and it features speed control via mechanical configuration of the rolling resistance. The FORWARD group is considering the impact introducing an additional sensor to capture the atittude of the walker and provide data of its speed and turning movements. This technology is explored further in section \ref{sssec:3_2stability}.\\

%% Matthew Research Here
\subsubsection{Current Computer Vision Object Detection Applications}

% General Synopsis of the current state of research
\noindent There have been multiple attempts to exploit the current state of machine learning and AI to bring guidance to the visually impaired. Many of the existing projects implement the YOLOv5 model to develop their object detection algorithms.\\

% Projection Ref #1
\noindent The project outlined in this paper \cite{CVRef1} seeks to provide guidance and navigation to the visually impaired through the use of a user worn chassis. The notable hardware used is a high quality MCU, \textit{The Jetson Nano}, which has 4 GB of on-board RAM, a 128-core GPU, and other efficient features. This board is designed for running AI/ML applications and for the purposes documented, performed well and as desired. \\

\noindent The software aspect of this project is mainly comprised through a object classification system, that uses the YOLO5 output to classify threat level of certain systems. By creating an "area of interest" represented by a 2D and 3D grid, they were able to perform calculations to achieve this. The figure demonstrating this concept is show below:
				
% Figure 1 in the paper
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{./Images/Figure1_Grid_Detection.png}
	\caption{\label{fig:Grid-Generatio}2D Grid with Safe Region Generation}
\end{figure}

\noindent Based on the figure above, once the effective safe region is generated, the MCU can begin performing calculations on the YOLO5 output to provide proper guidance to the system. And thus, this groups strategy in providing effective guidance through the implementation of YOLO5 and intentionally selected hardware to support AI/ML, with  applied math provides precision and accuracy to the user. \\

\noindent This project also implemented an audio feedback system. \\

% Projection Ref #2
\noindent Another project that used this technology to achieve a similar result is outline in this paper \cite{CVRef2}. \\


% Projection Ref #3

%% Morgan Research Here
\subsubsection{Motor and Steering Applications} 

