\subsection{Strategic Components}
% this is pretty much all research about the components themselves, which is summed up with the spec comparison table in 3_5-partselect

\subsubsection{Ultrasonic Sensors}
\noindent The range solution according to \textbf{\textit{time-of-flight sensing}} is modeled by the simple equation, where $d$ is distance, $t$ is time to send and return an ultrasonic pulse, and $v$ which is the speed of sound (340m/s):
$$d = 1/2 \times t \times v$$

\noindent \underline{\textit{HC-SR04}} ECHO pin outputs the time, $t$, taken by the emitted sound pulse (TX) to return (RX). In practice, to continuously sense and report range, the microcontroller will repeatedly send 40kHz pulses to the sensor's TRIG pin, which are redirected by the transmitter as a beam. Using I2C, the microcontroller can read $t$ and perform the range calculation.\\

\noindent \underline{\textit{HRLV-MaxSonar MB1000}} This sensor features auto calibration, range filtering and many more output options: pulse width, analog voltage, ranging start/stop (real time), and serial output. The designers also claim that this higher quality sensor does not skew the range reading based on the target size as others do. To solve for range, either connect Pin 3 to an analog-to-digital converter and calculate:
$$d (mm) = bits_{\{0..1023\}} \times 5$$
Alternatively, Pin 4 gives options for real time range data based on its pull-up voltage. It can return a range on command by MCU or default to 2Hz filtered range data "based on recent ranges." Finally, Pin 5 is serial output in RS232 format, which sends in ASCII, the range in millimeters.\\

\noindent \underline{\textit{RCWL-1X0X}} sensors allow for the same solutions method as the HC-SR04 and MB1000. These models feature both UART and I2C serial outputs, in which the distance is read directly from the device using:\\
UART: $Distance = ((BYTE_H << 16) + (BYTE_M << 8) + BYTE_L) /1000$\\
I2C: $Distance = ((BYTE_H\&It; \&It; 16) + (BYTE_M\&It: \&It; 8)+BYTE_L) /1000$\\

\noindent \underline{\textit{H2KA150KA1CD00}} operates at the high frequency of 150kHz. Unfortunately, the datasheet does not reveal much more about solving the range than the need to use a rectangular wavwdrive signal and a burst of 10 pulses. This returns an analog voltage output of the range. At a directivity angle of 8+/-2 degrees and a short range viability, this is not an ideal option for FORWARD.\\

\subsubsection{LiDAR Sensors}
\noindent \underline{\textit{LiDAR Lite V3}}
1 Write 0x04 to register 0x00.
2 Read register 0x01. Repeat until bit 0 (LSB) goes low.
3 Read two bytes from 0x8f (High byte 0x0f then low byte 0x10) to obtain the 16-bit measured distance in centimeters \\

\noindent \underline{\textit{XT-S1}} allows for active continuous measurement of range by reading start address $0x00$. Its output is hexadecimal, which is easily converted to a decimal reading in millimeters.\\

\noindent \underline{\textit{TF Family}} LiDAR sensors allow continuous ranging and also read by command. Note these have a 20cm dead zone. The designers note the possibility of light shedding on two parts of a surface, at which the range reading could be any value inbetween. They advise avoiding this for reliability. In the greater FORWARD context, we can consider the lesser of the readings for safety, so this is not necessarily an issue.\\

\subsubsection{Inertial Measurement Units}
\noindent Because of the simplistic nature of the application of this technology in FORWARD, extensive research is not as necessary as with the range sensors. We consider two main options.\\

\noindent \underline{\textit{BN-0055}} is a 9-DOF (axis) IMU, meaning it contains a 3-axis accelerator, 3-axis gyroscope, and a 3-axis geomagnetic sensor. This device is said to run sensor fusion on-board to provide accurate attitude information. It runs on $2.4-3.6V$ and draws $0.4mA$ of current when on its low power mode. It can be used in 3-axis only modes, meaning you can isolate the accelerator, gyroscope or magnetometer.\\

\noindent \underline{\textit{MPU-6050}} is one of the most popular IMU devices. It is 6-DOF (no magnetometer), and runs a DMP (digital motion processor) for motion fusion algorithms. Essentially, it calibrates itself, and is said to reduce gyro drift by eliminating cross-axis alignment errors between the gyroscope and accelerator. It operates at $3.6mA$ with a supply of $2.4-3.5V$.\\

\subsubsection{Computer Vision/AI Image Processing Models}
\underline{\textit{Ultralytics YOLO}} (You only look once) is an open source AI driven image processing model. The Ultralytics YOLO platform provides an AI Image processing Architecture that is malleable to the users demands, and for our case, would process the input image to detect if one of the five hazards is present, as well as provide a confidence rating for these predictions. To implement the object detection functionality to our specifications, minimal training, as well as coding must be performed. The benefits of this solution for our image classification system include zero cost and easy configurability which are both important aspects for our desired solution. The negatives include the needed man hours to train and implement this model for our purposes and time to run (anywhere from 0.1 seconds to 3 seconds). It also has a relatively high memory footprint (a few hundred MB). The time to predict along with the memory footprint could potentially exclude this from our options as we need to have classification under 1 second latency, ideally in the realm of a few hundred milliseconds and enough storage space for the model. \\
%https://www.freecodecamp.org/news/how-to-detect-objects-in-images-using-yolov8/#heading-how-to-get-started-with-yolov8 

\noindent \underline{\textit{FOMO}} (Faster objects, More objects) is a machine learning image processing algorithm that seeks to solve the problem of running high complexity algorithms (such as neural networks) on MCU's. In the documents referenced [HERE], the Arduino Nicla board is used to classify the objects in frame at a rate of 33 microseconds (30 SPS). The objects can be classified and processed through multiple methods, but all of which would be applicable to our purposes. This system also minimizes the memory usage by needing only 256 KB of memory to run and store these algorithms. On the FOMO website, they claim that this algorithm is compatible with many of the MCU's that we are considering for this project, some of which being an ESP32, Arduino Nicla, Raspberry Pi, and others. \\
%https://www.hackster.io/mjrobot/tinyml-made-easy-object-detection-with-nicla-vision-407ddd
%https://docs.edgeimpulse.com/docs/edge-impulse-studio/learning-blocks/object-detection/fomo-object-detection-for-constrained-devices

\noindent \underline{\textit{Edge Impulse}} is a website that is free to use and will allow for you to train models and then generate code for specific target devices. The way it works is, you upload your images for object detection, label and frame the objects, and then train the model. After this, you can choose your target device (Edge Impulse supports RaspberyrPi, ESP32, Arduino, and more), and generate a zip file for a library of object detection code. This is a simple to use, low complexity option that supports all of our considered MCUs.\\
%https://edgeimpulse.com/
%https://www.youtube.com/watch?v=bZIKVaD3dRk\

\subsubsection{Camera Technologies}
\label{sec:cam_tech}
\noindent \underline{\textit{ESP 32 CAM Board}} is a ESP32 processor based camera module that can transmit video data at high resolutions, which can be processed by our CV/Image processing solution. The module also has WIFI connectivity that can connect to an MCU to wirelessly transmit the video stream. The module has a 32-bit CPU with a max clock frequency of 240 MHz and 520 KB of built-in SRAM with an external 4MB PSRAM. The board module also runs on FreeRTOS. The included camera, OV2640 camera, has a 2 MP resolution, up to 1600 x 1200 and interfaces the controller board over a 24 pin interface bus. A more advanced sister product to the OV2640 is the OV5640 camera. This camera has 5 MP resolution, up to 2592 x 1944. In order to achieve our stretch requirement of depth perception analysis for guidance and navigation, this camera could be advantageous.\\

\noindent \underline{\textit{Oak-D Lite}} is an AI robotics specific camera, capable of running AI models such as open CV. The camera is able to run on-board AI architectures to achieve object classification, edge detection, and feature tracking. This technology allow for high accuracy with object detection, and introduce the ability to implement edge detection as a means to depth perception, which can be used for routing in our GNC subsystem. The Oak-D Lite has a 13 MP RGB camera with auto-focus, as well a 60axis sensor using an accelerometer and gyroscope. It also uses USB2 and USB3 for power and communication, which is simple to interface to a RaspberryPI. The camera can run 4K at 30 FPS or 1080P at 60 FPS.\\

\noindent \underline{\textit{Realtek AMB82-Mini IoT AI Camera}} is a lower cost option (\$25) to incorporate an AI object detection system within the camera and board. The specifications of the device are as follows: The MCU is an ARMv8M running up to 500 MHz, accompanied by an NPU with an Intelligent Engine capable of 0.4 TOPS. It features 128 MB of internal DDR2 memory. Connectivity options include dual-band Wi-Fi and Bluetooth 5.1.The audio code supports ADC/DAC/I2S, and the ISP/Video functionality includes both 1080p and 720p at 30FPS. The camera module is a JXF37 full HD CMOS image sensor with a resolution of 1920 x 1080 and a wide-view-angle FOV of 130Â°. The interface includes 1 microphone, 2 Micro USB B ports, 1 MicroSD card slot, and support for 3 UARTs, 2 SPIs, 1 I2C, 8 PWMs, 2 GDMAs, and a maximum of 23 GPIOs. This solution would free up processing power on our MCU which could be of great value given the high workload placed on our MCU including sensor fusion, motor controlling, image processing, and other needed functionalities. Also, due to the high memory capacity (128 MB DDR2), we could implement a higher quality detection model.\\


\subsubsection{MCU Technologies}
\noindent \underline{\textit{The ESP32 MCU}} is a small but powerful microcontroller with many features. These features include UART, SPI, and I2C communications, 4 MB - 8 MB of flash, with some PSRAM options. These boards also have WIFI and Bluetooth connectivity. The ESP32 series of MCU's range anywhere from \$9 to \$12. The current existing boards are ESP32-DevKitC-32E, ESP32-DevKitC-32UE, ESP32-DevKitCVE, ESP32-DevKitCVIE, and ESP32-DevKitCS1. The main difference between these boards are size and types of memory (4 MB - 8 MB and PSRAM/FLASH) along with antenna type (IPEX vs PCB). The ESP32 family also has a variety of products, such as camera modules, motor controllers, and others. The ESP32 is also easy to program as it is comptabile with the Arduino IDE.\\
%https://www.espressif.com/en/products/devkits/esp32-devkitc

\noindent \underline{\textit{The RaspberryPI 4 model B}} is a small computer with a 64-bit quad core processor running at 1.5GHz. The RaspberryPi has both dual-band 2.4GHz and 5GHz wireless LAN and Bluetooth 5.0/BLE. The Pi also has Ethernet capabilities along with a 40 pin GPIO header. It uses the Broadcom BCM2711 processor chip and comes with memory options of 1GB, 2GB, 4GB or 8GB LPDDR4-3200 SDRAM, as well as having a micro-SD slot for additional memory capabilities. The board also features many I/O ports, such as 2 USB 3.0 ports, 2 USB 2.0 ports, 2 HDMI ports, and a 2-lane MIPI CSI camera port. The board ranges from \$30 to \$50 and can be purchased online.
%https://www.pishop.us/product/raspberry-pi-4-model-b-2gb/?src=raspberrypi
